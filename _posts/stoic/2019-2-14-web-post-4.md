---
layout: postpage
title: "Stoic Ethics Post 4"
image: /ethical-computing-institute/css/zeno.png
epicurus-postpage: true
subpage: false
coursepage: false
categories: stoic
---

### Legal Brief on IBM's Relationship with Nazi Germany
Relevant Stakeholders:
* IBM
* Persons entitled to Holocaust reparations, who have taken part in several suits agains IBM.
* Allied governments (responsible for issuing punishment postwar), particularly the United States government (where IBM is based), whose laws may have been subverted
* The Nazi Party: While no longer an active stakeholder, the lack of records surrounding these actions make details of their crimes unclear. Clarifications will be part of the public record no matter how they interact

IBM conducted all business in Germany through its subsidiary, Deutsche Hollerith Maschinen Gesellschaft (Dehomag).

Dehomag had strong business relationships in Germany before WWII. IBM was a popular vendor of census solutions, collecting demographic data such as religion along with family relations. This would be one of the first databases capable of solving the Nazi problem of identifying Judaism as a bloodline. However, most of these transactions were seen as optimizations of census taking and many countries made similar arrangements with IBM.

IBM machines were not sold to the Nazis, but leased, this meant that they were maintained on a biweekly schedule. Punch cards were inventoried and kept in constant supply. Continued operations of the Holocaust require continuous material and technical expertise provided by IBM.

Officials in Nazi Germany held IBM in high regard on both a personal level, as well as technical. Many of Dehomag’s upper management were openly devout Nazis. IBM CEO at the time, Thomas Watson, had met with Hitler and visited Germany several times over the years of 1930-1945. The German government also attempted to award Watson a medal for his company’s contributions to economic reforms.

Circumstances seem to suggest that IBM’s New York office. Several sources claim that IBM New York representatives spent protracted amounts of time in Berlin and Geneva performing oversight, suggesting a nontrivial awareness of business in the region. CEO Watson was also in favor of a European school for training additional technicians for machines. While this could have been for any number of benign reasons, it at the very suggests that Watson either hadn’t lost control of IBM operations in Europe, or was unconcerned about it to the point of negligence.

Critics of IBM acknowledge only one statement addressing IBM’s involvement in the holocaust, which states that “IBM and its employees around the world find the atrocities committed by the Nazi regime abhorrent and categorically condemn any actions which aided their unspeakable acts.” On the topic of records, IBM claims that they have complied to the best of their ability, but that full recovery of records of postwar Germany was impossible, saying:

“IBM does not have much information about this period or the operations of Dehomag. Most documents were destroyed or lost during the war. The documents that did exist were placed in the public domain some time ago.”

Most authors note that IBM has refused to cooperate on writings.

While the loss of information in Europe postwar is not a uniquely IBM claim, Edwin Black and a team of researchers were able to collect a more complete record of Dehormag’s relationship with Nazi Germany and IBM’s relationship with Derhomad in the 1930s and 1940s, which was published in IBM and the Holocaust. This suggests that whatever the present states of IBM’s official records, some recovery/updating is possible. This is in direct contradiction to IBM’s claim that “based on everything the company has seen to date, there appear to be no new facts or findings that bear on this important issue and period.”

It can be established that IBM had business ties with Nazi Germany through Dehomag, and maintained maintenance of the machines used in the holocaust. IBM has been reticent on the issue ever since and made little measurable reparation efforts relating to the holocaust, but defenders of IBM point out that this situation is not unique to IBM's business in Germany (see General Motors) and all rulings have found these companies free of liability for decades.

Stoic ethics takes a clear stance in these issues. Things that are truly good are good in all cases, failing to strive
for this represents a deficiency of virtue. IBM's collections of census data and construction of custom geneology-tracing
machines were clearly not good in all cases, as we saw their applications to genocide.
This potential for harm is technically damning, but IBM made several other questionable decisions that were certainly 
not good in all cases.

Evidence suggests that technicians who could have reported on the progress of the Holocaust to IBM were directly at sites 
central to the Holocaust, including the concentration camps. However, IBM claims ignorance as to the use of their machines.
If IBM had information and is now lying, that would be obviously evil, but ignorance does not absolve IBM in this case. If
IBM management was truly unaware of the situation in the camps, then they allowed their subsidiary to hide immoral acts
committed with IBM equipment under IBM's name. There's no way IBM could allow insubordination on such a scale without displaying high levels of negligence (which again would not be virtuous in all cases as we have seen).

Further evidencing IBM's involvement is the presence of their management in Europe and the acceptance of the special
commision for the Hollerherth system. IBM invested clear amounts of mental, physical, and capital efforts towards creating
the tools that would later be turned towards the Holocaust and maintained ownership of these tools, apparently without
any understanding of how they were used. Such behavior does not seem to display intentions to mitigate negative consequences 
from these actions, which is of course inconsistent with the directive to do things that are good in all circumstances.



### Ethical Analysis on the Implementation of a Muslim Registry
Now nearing the end of a four-year term, President Donald Trump seems to be at the center of the big data—its privacy, accuracy, and use—controversy. Although his reign did not see the implementation of a promised Muslim registry come to fruition, it did see people raising well over 20 million dollars to instantiate a border wall. Additionally, Trump and his campaign have been accused, and for the most part found guilty of, leveraging big data to target specific audiences to win the election, specifically by creating very precise, intimate profiles and targeting consumers. With this kind of xenophobia fueling a huge population, the fear of a massively racist use of big data is very real. At the heart of the controversy lie a few main points, especially pertaining to the idea of building a Muslim registry that would document and go after all Muslims living in, migrating to, or leaving the United States. 

The problem starts with data brokers and large privately held data companies aggregating and analyzing huge amounts of personal information to create very private, unique profiles of nearly every US citizen. The key here is that data does not necessarily have to come from one source or be explicitly given to these companies. Once an individual essentially “waves” usage rights in order to use a new app or device, private companies can access and amass that data. This data can then be analyzed and sold to the highest bidder, no matter what that bidder intends to use the data for. While the government is forbidden from profiling its citizens via data as per the Privacy Act of 1974, nothing forbids government institutions from purchasing and using this private data from a privately held company. This lack of legislature regarding large data privacy has left a lot of gray areas in legality of handling big data, and exactly how and what it can be used for. As a result, a Muslim registry really isn’t that unfathomable or difficult to create. In fact, many companies affirmed that something like this would be easy to do—even if it was a bit unethical. In response to this threat of an attack on human rights, some technical professionals are pledging to refuse to cooperate in building discriminatory databases, saying that they will quit their jobs if they are forced to do so in addition to speaking out against the company.

With the case laid out, it is clear that a Muslim registry would be completely and totally unethical. Not only does systematic racism and profiling go against the stoic ethical framework since it creates and nourishes bias and inequalities, but any algorithm or database that attempts this task is guaranteed to have false positives—where the algorithm incorrectly profiles a person—which confirms that the process is biased. In the article by Tanya O’Carroll, she says, “Such databases pose numerous risks of facilitating discrimination against people. But still other problems arise due to the fact that these databases are not perfect.” A system in which failure is an option—not to mention when that failure has detrimental ramifications—is not moral. Additionally, O’Carroll writes, “Data brokers and data analytic companies — like all businesses — have a responsibility to respect human rights, which means making sure they don’t cause or contribute to human rights abuses.” Since data brokers and analysts are private companies, they do have a corporate social responsibility to protect and defend human rights, and to not exploit private data for financial gain. An organization should be bound by a rational and fair code of ethics, devised by not only the investors of a company, but the consumers, and all those who are affecting by the corporation, especially since big data is so unregulated. This is summed up well by Chris Dixon in his article when he says, “Just because it is legal does not make it right.” More legislation and regulation are needed for these big data companies, but companies are also obligated to protect and defend human rights and the privacy of their customers. 

The creation of a Muslim registry would be equally immoral if the government created it, perhaps even more so. People’s data should not be used to make discriminatory assumptions, and the government should not be using people’s data to create a Muslim registry. In fact, the government should be taking a firmer stance and introducing much more rigid regulations regarding big data, since its job is to protect the rights and privacy of the citizens it serves, and constitutionally, this is regardless of any religious or ethnic affiliation. Again, the data and the analysis are imperfect, and people are not giving their permission for their data to be aggregated and consumed to advance government discrimination.  Often times, the personal data that an individual elects to give up is small and insignificant in itself, but when this bit of explicit information is pooled with enough other pieces over time, it is possible to implicitly comb the data and draw assumptions that create a personal profile (and bias) that can be leveraged by private or government institutions—and could just be plain inaccurate!

Tech professionals, especially who those who work for the large data brokers, are taking a stand, but companies shouldn’t be putting their employees in this position in the first place. If more legislation was passed that specifically outlined how data can be stored, analyzed, and applied, and companies took a stronger stance and owned their corporate social responsibility to their customers and their customer’s privacy, and to society in general, the big data market would pose much less of a threat to human rights and minimize the risk of discriminatory exploitation. 
