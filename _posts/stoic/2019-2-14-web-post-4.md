---
layout: postpage
title: "Stoic Ethics Post 3"
image: /ethical-computing-institute/css/zeno.png
epicurus-postpage: true
subpage: false
coursepage: false
categories: stoic
---
### Ethical Analysis on the Implementation of a Muslim Registry
Now nearing the end of a four-year term, President Donald Trump seems to be at the center of the big data—its privacy, accuracy, and use—controversy. Although his reign did not see the implementation of a promised Muslim registry come to fruition, it did see people raising well over 20 million dollars to instantiate a border wall. Additionally, Trump and his campaign have been accused, and for the most part found guilty of, leveraging big data to target specific audiences to win the election, specifically by creating very precise, intimate profiles and targeting consumers. With this kind of xenophobia fueling a huge population, the fear of a massively racist use of big data is very real. At the heart of the controversy lie a few main points, especially pertaining to the idea of building a Muslim registry that would document and go after all Muslims living in, migrating to, or leaving the United States. 
The problem starts with data brokers and large privately held data companies aggregating and analyzing huge amounts of personal information to create very private, unique profiles of nearly every US citizen. The key here is that data does not necessarily have to come from one source or be explicitly given to these companies. Once an individual essentially “waves” usage rights in order to use a new app or device, private companies can access and amass that data. This data can then be analyzed and sold to the highest bidder, no matter what that bidder intends to use the data for. While the government is forbidden from profiling its citizens via data as per the Privacy Act of 1974, nothing forbids government institutions from purchasing and using this private data from a privately held company. This lack of legislature regarding large data privacy has left a lot of gray areas in legality of handling big data, and exactly how and what it can be used for. As a result, a Muslim registry really isn’t that unfathomable or difficult to create. In fact, many companies affirmed that something like this would be easy to do—even if it was a bit unethical. In response to this threat of an attack on human rights, some technical professionals are pledging to refuse to cooperate in building discriminatory databases, saying that they will quit their jobs if they are forced to do so in addition to speaking out against the company.
With the case laid out, it is clear that a Muslim registry would be completely and totally unethical. Not only does systematic racism and profiling go against the stoic ethical framework since it creates and nourishes bias and inequalities, but any algorithm or database that attempts this task is guaranteed to have false positives—where the algorithm incorrectly profiles a person—which confirms that the process is biased. In the article by Tanya O’Carroll, she says, “Such databases pose numerous risks of facilitating discrimination against people. But still other problems arise due to the fact that these databases are not perfect.” A system in which failure is an option—not to mention when that failure has detrimental ramifications—is not moral. Additionally, O’Carroll writes, “Data brokers and data analytic companies — like all businesses — have a responsibility to respect human rights, which means making sure they don’t cause or contribute to human rights abuses.” Since data brokers and analysts are private companies, they do have a corporate social responsibility to protect and defend human rights, and to not exploit private data for financial gain. An organization should be bound by a rational and fair code of ethics, devised by not only the investors of a company, but the consumers, and all those who are affecting by the corporation, especially since big data is so unregulated. This is summed up well by Chris Dixon in his article when he says, “Just because it is legal does not make it right.” More legislation and regulation are needed for these big data companies, but companies are also obligated to protect and defend human rights and the privacy of their customers. 
The creation of a Muslim registry would be equally immoral if the government created it, perhaps even more so. People’s data should not be used to make discriminatory assumptions, and the government should not be using people’s data to create a Muslim registry. In fact, the government should be taking a firmer stance and introducing much more rigid regulations regarding big data, since its job is to protect the rights and privacy of the citizens it serves, and constitutionally, this is regardless of any religious or ethnic affiliation. Again, the data and the analysis are imperfect, and people are not giving their permission for their data to be aggregated and consumed to advance government discrimination.  Often times, the personal data that an individual elects to give up is small and insignificant in itself, but when this bit of explicit information is pooled with enough other pieces over time, it is possible to implicitly comb the data and draw assumptions that create a personal profile (and bias) that can be leveraged by private or government institutions—and could just be plain inaccurate!
Tech professionals, especially who those who work for the large data brokers, are taking a stand, but companies shouldn’t be putting their employees in this position in the first place. If more legislation was passed that specifically outlined how data can be stored, analyzed, and applied, and companies took a stronger stance and owned their corporate social responsibility to their customers and their customer’s privacy, and to society in general, the big data market would pose much less of a threat to human rights and minimize the risk of discriminatory exploitation. 
